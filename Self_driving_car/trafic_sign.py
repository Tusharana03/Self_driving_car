# -*- coding: utf-8 -*-
"""trafic_sign

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WS7NmI5v3ZcjtjQ25wV9fxFZtbw8vGR5
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle
import pandas as pd
import random
np.random.seed(0)

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

with open('german-traffic-signs/train.p','rb') as f:
  train_data = pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
  val_data = pickle.load(f)
with open('german-traffic-signs/test.p','rb') as f:
  test_data = pickle.load(f)

x_train , y_train = train_data['features'], train_data['labels']
x_val , y_val = val_data['features'] , val_data['labels']
x_test , y_test = test_data['features'], test_data['labels']

print(x_train.shape)
print(x_test.shape)
print(x_val.shape)
print(y_train.shape)

assert(x_train.shape[0]==y_train.shape[0]),'the no. of images is not equal to no of labels'
assert(x_val.shape[0]==y_val.shape[0]),'the no. of images is not equal to no of labels'
assert(x_test.shape[0]==y_test.shape[0]),'the no. of images is not equal to no of labels'
assert(x_train.shape[1:]==(32,32,3)),'the dimension of the images are not 32*32*30'
assert(x_test.shape[1:]==(32,32,3)),'the dimension of the images are not 32*32*30'
assert(x_val.shape[1:]==(32,32,3)),'the dimension of the images are not 32*32*30'

data = pd.read_csv('german-traffic-signs/signnames.csv')
print(data)

num_of_samples = []
cols = 5
num_of_classes = 43
fig, axs = plt.subplots(nrows=num_of_classes, ncols=cols,figsize=(5,50))
fig.tight_layout()
for i in range(cols):
  for j, row in data.iterrows():
    x_selected = x_train[y_train == j]
    axs[j][i].axis('off')
    axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected)-1)),:,:],cmap= plt.get_cmap('gray'))
    if i == 2:
      axs[j][i].set_title(str(j)+ "-" + row['SignName'])
      num_of_samples.append(len(x_selected))

import cv2
plt.imshow(x_train[1000])
plt.axis('off')
print(x_train[1000].shape)
print(y_train[1000])

def grayscale(img):
  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  return img

img = grayscale(x_train[1000])
plt.imshow(img,cmap= plt.get_cmap('gray'))
plt.axis('off')
print(img.shape)

def equalize(img):
  img = cv2.equalizeHist(img)
  return img

img = equalize(img)
plt.imshow(img,cmap=plt.get_cmap('gray'))
plt.axis('off')
print(img.shape)

def preprocessing(img):
  img = grayscale(img)
  img = equalize(img)
  img = img/255
  return img

x_train = np.array(list(map(preprocessing,x_train)))
x_val = np.array(list(map(preprocessing,x_val)))
x_test = np.array(list(map(preprocessing,x_test)))
print(x_train.shape)

plt.imshow(x_train[random.randint(0,len(x_train)-1)])
plt.axis('off')
print(x_train.shape)

x_train = x_train.reshape(34799,32,32,1)
x_test = x_test.reshape(12630,32,32,1)
x_val = x_val.reshape(4410,32,32,1)

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(width_shift_range=0.1 , height_shift_range=0.1 , zoom_range=0.2, shear_range=0.1,rotation_range=10)
datagen.fit(x_train)

batches = datagen.flow(x_train,y_train, batch_size=20)
x_batch, y_batch = next(batches)
print(x_batch.shape)
fig, axs = plt.subplots(1,15, figsize=(20,5))
fig.tight_layout()
for i in range(15):
  axs[i].imshow(x_batch[i].reshape(32,32))
  axs[i].axis('off')

print(x_test.shape)
print(x_train.shape)
print(x_val.shape)

y_train = to_categorical(y_train,43)
y_val = to_categorical(y_val,43)
y_test = to_categorical(y_test,43)
print(len(x_train))

def leNt_model():
  model = Sequential()

  model.add(Conv2D(filters=60,kernel_size=(5,5),input_shape =(32,32,1),activation='relu'))
  model.add(Conv2D(filters=60,kernel_size=(5,5),activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))

  model.add(Conv2D(filters=30,kernel_size=(3,3),activation="relu"))
  model.add(Conv2D(filters=30,kernel_size=(3,3),activation="relu"))
  model.add(MaxPooling2D(pool_size=(2,2)))
  #model.add(Dropout(rate=0.5))

  model.add(Flatten())
  model.add(Dense(units=500,activation='relu'))
  #model.add(Dropout(rate=0.5))
  model.add(Dense(units=43,activation='softmax'))
  model.compile(Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])
  return model


model = leNt_model()
print(model.summary())

history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=17), steps_per_epoch=2000, epochs=10, validation_data=(x_val,y_val), shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss','val_loss'])
plt.xlabel('epoch')

score = model.evaluate(x_test,y_test, verbose=0)
print('test score:',score[0])
print('test accuracy:',score[1])

url1 = "https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg"
url2 = "https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg"
url3 = 'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'
url4 = 'https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg'
url5 = 'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg'



import requests
from PIL import Image
def image_from_url(url):
  response = requests.get(url,stream = True)
  img_test = Image.open(response.raw)
  img_array = np.asarray(img_test)
  resize_img = cv2.resize(img_array,(32,32))
  img = preprocessing(resize_img)
  img = img.reshape(1,32,32,1)
  return img

img = image_from_url(url4)
prediction = np.argmax(model.predict(img), axis=-1)
print('predicition is: ', prediction)